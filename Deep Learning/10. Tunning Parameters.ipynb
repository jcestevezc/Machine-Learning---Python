{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('irrigation_machine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sensor_0</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_14</th>\n",
       "      <th>sensor_15</th>\n",
       "      <th>sensor_16</th>\n",
       "      <th>sensor_17</th>\n",
       "      <th>sensor_18</th>\n",
       "      <th>sensor_19</th>\n",
       "      <th>parcel_0</th>\n",
       "      <th>parcel_1</th>\n",
       "      <th>parcel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sensor_0  sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  \\\n",
       "0           0       1.0       2.0       1.0       7.0       0.0       1.0   \n",
       "1           1       5.0       1.0       3.0       5.0       2.0       2.0   \n",
       "2           2       3.0       1.0       4.0       3.0       4.0       0.0   \n",
       "3           3       2.0       2.0       4.0       3.0       5.0       0.0   \n",
       "4           4       4.0       3.0       3.0       2.0       5.0       1.0   \n",
       "\n",
       "   sensor_6  sensor_7  sensor_8  ...  sensor_13  sensor_14  sensor_15  \\\n",
       "0       1.0       4.0       0.0  ...        8.0        1.0        0.0   \n",
       "1       1.0       2.0       3.0  ...        4.0        5.0        5.0   \n",
       "2       1.0       6.0       0.0  ...        3.0        3.0        1.0   \n",
       "3       3.0       2.0       2.0  ...        4.0        1.0        1.0   \n",
       "4       3.0       1.0       1.0  ...        1.0        3.0        2.0   \n",
       "\n",
       "   sensor_16  sensor_17  sensor_18  sensor_19  parcel_0  parcel_1  parcel_2  \n",
       "0        2.0        1.0        9.0        2.0         0         1         0  \n",
       "1        2.0        2.0        2.0        7.0         0         0         0  \n",
       "2        0.0        3.0        1.0        0.0         1         1         0  \n",
       "3        4.0        1.0        3.0        2.0         0         0         0  \n",
       "4        2.0        1.0        1.0        0.0         1         1         0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "sensor_0      float64\n",
       "sensor_1      float64\n",
       "sensor_2      float64\n",
       "sensor_3      float64\n",
       "sensor_4      float64\n",
       "sensor_5      float64\n",
       "sensor_6      float64\n",
       "sensor_7      float64\n",
       "sensor_8      float64\n",
       "sensor_9      float64\n",
       "sensor_10     float64\n",
       "sensor_11     float64\n",
       "sensor_12     float64\n",
       "sensor_13     float64\n",
       "sensor_14     float64\n",
       "sensor_15     float64\n",
       "sensor_16     float64\n",
       "sensor_17     float64\n",
       "sensor_18     float64\n",
       "sensor_19     float64\n",
       "parcel_0        int64\n",
       "parcel_1        int64\n",
       "parcel_2        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset stats: \n",
      "         Unnamed: 0     sensor_0     sensor_1     sensor_2     sensor_3  \\\n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
      "mean    999.500000     1.437000     1.659000     2.654500     2.674500   \n",
      "std     577.494589     1.321327     1.338512     1.699286     1.855875   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%     499.750000     0.000000     1.000000     1.000000     1.000000   \n",
      "50%     999.500000     1.000000     1.000000     2.000000     2.000000   \n",
      "75%    1499.250000     2.000000     2.000000     4.000000     4.000000   \n",
      "max    1999.000000     8.000000     9.000000    10.000000    11.000000   \n",
      "\n",
      "          sensor_4     sensor_5     sensor_6     sensor_7     sensor_8  ...  \\\n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
      "mean      2.887500     1.411000     3.315500     4.201500     1.214000  ...   \n",
      "std       1.816451     1.339394     2.206444     2.280241     1.386782  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       2.000000     0.000000     2.000000     3.000000     0.000000  ...   \n",
      "50%       3.000000     1.000000     3.000000     4.000000     1.000000  ...   \n",
      "75%       4.000000     2.000000     5.000000     6.000000     2.000000  ...   \n",
      "max      12.000000     7.000000    13.000000    12.000000     8.000000  ...   \n",
      "\n",
      "         sensor_13    sensor_14    sensor_15    sensor_16    sensor_17  \\\n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
      "mean      2.731500     3.416000     1.206500     2.325000     1.729500   \n",
      "std       1.774537     1.960578     1.258034     1.715181     1.561265   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       1.000000     2.000000     0.000000     1.000000     0.000000   \n",
      "50%       2.000000     3.000000     1.000000     2.000000     1.000000   \n",
      "75%       4.000000     5.000000     2.000000     3.000000     3.000000   \n",
      "max      11.000000    11.000000     6.000000    10.000000    11.000000   \n",
      "\n",
      "        sensor_18    sensor_19    parcel_0     parcel_1     parcel_2  \n",
      "count  2000.00000  2000.000000  2000.00000  2000.000000  2000.000000  \n",
      "mean      2.27450     1.813500     0.63550     0.730500     0.212000  \n",
      "std       1.67169     1.469285     0.48141     0.443811     0.408827  \n",
      "min       0.00000     0.000000     0.00000     0.000000     0.000000  \n",
      "25%       1.00000     1.000000     0.00000     0.000000     0.000000  \n",
      "50%       2.00000     2.000000     1.00000     1.000000     0.000000  \n",
      "75%       3.00000     3.000000     1.00000     1.000000     0.000000  \n",
      "max      10.00000     7.000000     1.00000     1.000000     1.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Describe the data\n",
    "print('Dataset stats: \\n', data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations per class 0: \n",
      " 1    1271\n",
      "0     729\n",
      "Name: parcel_0, dtype: int64\n",
      "Observations per class 1: \n",
      " 1    1461\n",
      "0     539\n",
      "Name: parcel_1, dtype: int64\n",
      "Observations per class 2: \n",
      " 0    1576\n",
      "1     424\n",
      "Name: parcel_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of observations of each class\n",
    "print('Observations per class 0: \\n', data['parcel_0'].value_counts())\n",
    "print('Observations per class 1: \\n', data['parcel_1'].value_counts())\n",
    "print('Observations per class 2: \\n', data['parcel_2'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data[['parcel_0','parcel_1','parcel_2']]\n",
    "X = data.drop(['parcel_0','parcel_1','parcel_2','Unnamed: 0'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the Sequential model and Dense layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Creates a model given an activation and learning rate\n",
    "def create_model(learning_rate=0.01, activation='relu'):\n",
    "  \n",
    "    # Create an Adam optimizer with the given learning rate\n",
    "    opt = Adam(lr=learning_rate)\n",
    "\n",
    "    # Create your binary classification model  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(30,), activation=activation))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KerasClassifier from keras wrappers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create a KerasClassifier\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "# Define the parameters to try out\n",
    "params = {'activation': ['relu', 'tanh'], \n",
    "          'batch_size': [32, 128, 256], \n",
    "          'epochs': [50, 100, 200], \n",
    "          'learning_rate': [0.1, 0.01, 0.001]}\n",
    "\n",
    "# Create a randomize search cv object passing in the parameters to try\n",
    "random_search = RandomizedSearchCV(model, param_distributions = params, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x00000250455AF5C0>,\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'activation': ['relu', 'tanh'],\n",
       "                                        'batch_size': [32, 128, 256],\n",
       "                                        'epochs': [50, 100, 200],\n",
       "                                        'learning_rate': [0.1, 0.01, 0.001]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Error when checking input: expected dense_1_input to have shape (30,) but got array with shape (20,)\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Error when checking input: expected dense_4_input to have shape (30,) but got array with shape (20,)\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy was: nan\n",
      "With a standard deviation of: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Error when checking input: expected dense_7_input to have shape (30,) but got array with shape (20,)\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import KerasClassifier from keras wrappers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a KerasClassifier\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 50, batch_size = 128, verbose = 0)\n",
    "\n",
    "# Calculate the accuracy score for each fold\n",
    "kfolds = cross_val_score(model, X, y, cv = 3)\n",
    "\n",
    "# Print the mean accuracy\n",
    "print('The mean accuracy was:', kfolds.mean())\n",
    "\n",
    "# Print the accuracy standard deviation\n",
    "print('With a standard deviation of:', kfolds.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
